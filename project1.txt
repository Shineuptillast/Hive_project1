Create a new directory in Hadoop file system 

hdfs dfs -mkdir /user/project1

Transfer the dataset from Local file system to hdfs 

hdfs dfs -put ./vehicle_data.csv /user/project1/

Creating an external table for the analysis

create database project1;

use project1;


create external table vehicle_sales(
ord_no int,
quantity int,
price_foreach float,
prd_lno int,
sales float,
status string,
qtr_id int,
month int,
year_id int,
product_type string,
msrp int,
product_code string,
phone string,
city string,
state string,
postal_code string,
country string,
territory string,
contact_lname string,
contact_fname string,
deal_size string
)
row format delimited
fields terminated by ','
location '/user/project1';


describe vehicle_sales;

describe formatted vehicle_sales;


Creating an Internal Table storing data in ORC format:

create table vehicle_sales_orc(
ord_no int,
quantity int,
price_foreach float,
prd_lno int,
sales float,
status string,
qtr_id int,
month int,
year_id int,
product_type string,
msrp int,
product_code string,
phone string,
city string,
state string,
postal_code string,
country string,
territory string,
contact_lname string,
contact_fname string,
deal_size string
)
stored as orc;

from vehicle_sales insert overwrite table vehicle_sales_orc select *;










